# -*- coding: utf-8 -*-
"""SML-Final.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1XwA_oUiSdKCthjCCz4IiflUFd6d5LtO9
"""

import os
import random
import numpy as np
import torch
import torch.nn.utils.prune as prune
from torch.utils.data import DataLoader, RandomSampler, SequentialSampler, TensorDataset
from transformers import DistilBertForSequenceClassification, DistilBertTokenizer, get_linear_schedule_with_warmup
from torch.optim import AdamW
from datasets import load_dataset
from tqdm import tqdm
from sklearn.metrics import accuracy_score
import matplotlib.pyplot as plt

# Set random seed for reproducibility
def set_seed(seed=42):
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed_all(seed)

set_seed(42)

# Configuration
MAX_SEQ_LENGTH = 128
BATCH_SIZE = 32
LEARNING_RATE = 2e-5
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
OUTPUT_DIR = "./sst2_pruned_model"

print(f"Using device: {DEVICE}")

# Load tokenizer
print("\nLoading tokenizer...")
tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')

# Load and prepare dataset
def load_sst2_data(split='train'):
    print(f"Loading SST-2 {split} dataset...")
    dataset = load_dataset('glue', 'sst2', split=split)

    input_ids = []
    attention_masks = []
    labels = []

    for example in tqdm(dataset, desc=f"Tokenizing"):
        encoded = tokenizer(
            example['sentence'],
            max_length=MAX_SEQ_LENGTH,
            padding='max_length',
            truncation=True,
            return_tensors='pt'
        )
        input_ids.append(encoded['input_ids'].squeeze(0))
        attention_masks.append(encoded['attention_mask'].squeeze(0))
        labels.append(example['label'])

    return TensorDataset(
        torch.stack(input_ids),
        torch.stack(attention_masks),
        torch.tensor(labels, dtype=torch.long)
    )

# Evaluation function
def evaluate_model(model, dataset):
    model.eval()
    dataloader = DataLoader(dataset, batch_size=64, shuffle=False)

    all_preds = []
    all_labels = []
    total_loss = 0

    with torch.no_grad():
        for batch in tqdm(dataloader, desc="Evaluating"):
            input_ids = batch[0].to(DEVICE)
            attention_mask = batch[1].to(DEVICE)
            labels = batch[2].to(DEVICE)

            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)
            total_loss += outputs.loss.item()

            preds = torch.argmax(outputs.logits, dim=1)
            all_preds.extend(preds.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())

    accuracy = accuracy_score(all_labels, all_preds)
    avg_loss = total_loss / len(dataloader)

    return accuracy, avg_loss

# ============================================================================
# STEP 1: Train baseline model without pruning
# ============================================================================

print("\n" + "="*80)
print("STEP 1: TRAINING BASELINE MODEL (Without Pruning)")
print("="*80)

# Check if baseline model already exists
baseline_model_path = os.path.join(OUTPUT_DIR, 'baseline_model')

if os.path.exists(baseline_model_path):
    print(f"\n‚úì Found existing baseline model at: {baseline_model_path}")
    print("  Loading saved model... (Skip training to save time!)")
    model = DistilBertForSequenceClassification.from_pretrained(baseline_model_path)
    model.to(DEVICE)
    val_dataset = load_sst2_data('validation')
    baseline_accuracy, _ = evaluate_model(model, val_dataset)
    print(f"  Baseline accuracy: {baseline_accuracy:.4f}")
    print("\n  To retrain, delete the folder and run again.")
else:
    print("\n‚úó No existing model found. Training from scratch...")

    # Load datasets
    train_dataset = load_sst2_data('train')
    val_dataset = load_sst2_data('validation')

    # Initialize model
    print("\nInitializing DistilBERT model...")
    model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=2)
    model.to(DEVICE)

    # Training setup
    train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)
    num_epochs = 3
    total_steps = len(train_dataloader) * num_epochs
    warmup_steps = int(0.1 * total_steps)

    optimizer = AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=0.01)
    scheduler = get_linear_schedule_with_warmup(optimizer, warmup_steps, total_steps)

    # Train baseline model
    print(f"\nTraining for {num_epochs} epochs...")
    print(f"Total training steps: {total_steps}")

    best_accuracy = 0

    for epoch in range(num_epochs):
        print(f"\nEpoch {epoch + 1}/{num_epochs}")
        model.train()
        total_loss = 0

        progress_bar = tqdm(train_dataloader, desc="Training")
        for batch in progress_bar:
            input_ids = batch[0].to(DEVICE)
            attention_mask = batch[1].to(DEVICE)
            labels = batch[2].to(DEVICE)

            model.zero_grad()
            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)
            loss = outputs.loss

            loss.backward()
            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)
            optimizer.step()
            scheduler.step()

            total_loss += loss.item()
            progress_bar.set_postfix({'loss': f'{loss.item():.4f}'})

        avg_train_loss = total_loss / len(train_dataloader)

        # Evaluate
        val_accuracy, val_loss = evaluate_model(model, val_dataset)
        print(f"Epoch {epoch + 1} - Train Loss: {avg_train_loss:.4f}, Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}")

        if val_accuracy > best_accuracy:
            best_accuracy = val_accuracy

    # Save baseline model
    os.makedirs(baseline_model_path, exist_ok=True)
    model.save_pretrained(baseline_model_path)
    tokenizer.save_pretrained(baseline_model_path)

    print(f"\n‚úì Baseline model saved to: {baseline_model_path}")
    baseline_accuracy, _ = evaluate_model(model, val_dataset)
    print(f"  Baseline test accuracy: {baseline_accuracy:.4f}")

# ============================================================================
# STEP 2: Fine-tune with magnitude-based pruning
# ============================================================================

print("\n" + "="*80)
print("STEP 2: FINE-TUNING WITH MAGNITUDE-BASED PRUNING (50% ‚Üí 80%)")
print("="*80)

# Reload model for pruning
model = DistilBertForSequenceClassification.from_pretrained(baseline_model_path)
model.to(DEVICE)

# Identify layers to prune (exclude classifier)
prunable_layers = []
for name, module in model.named_modules():
    if isinstance(module, torch.nn.Linear) and 'classifier' not in name and 'pre_classifier' not in name:
        prunable_layers.append((name, module))

print(f"\nFound {len(prunable_layers)} layers to prune")

# Pruning schedule parameters
initial_sparsity = 0.50
final_sparsity = 0.80
pruning_epochs = 2
validation_split = 0.1

# Calculate number of training steps for pruning
num_train_samples = int(len(train_dataset) * (1 - validation_split))
steps_per_epoch = num_train_samples // BATCH_SIZE
total_pruning_steps = steps_per_epoch * pruning_epochs

print(f"Pruning schedule: {initial_sparsity*100}% ‚Üí {final_sparsity*100}% sparsity")
print(f"Pruning will be applied over {total_pruning_steps} steps ({pruning_epochs} epochs)")

def get_sparsity_for_step(step, total_steps, initial, final):
    """Polynomial decay schedule for sparsity"""
    if step >= total_steps:
        return final
    progress = step / total_steps
    return initial + (final - initial) * (progress ** 3)

def apply_pruning(model, layers, sparsity):
    """Apply L1 magnitude-based pruning"""
    for name, module in layers:
        if prune.is_pruned(module):
            prune.remove(module, 'weight')
        prune.l1_unstructured(module, name='weight', amount=sparsity)

def calculate_sparsity(model, layers):
    """Calculate actual sparsity in model"""
    total_params = 0
    zero_params = 0

    for name, module in layers:
        if prune.is_pruned(module):
            weight = module.weight_orig * module.weight_mask
        else:
            weight = module.weight

        total_params += weight.numel()
        zero_params += (weight == 0).sum().item()

    return zero_params / total_params if total_params > 0 else 0

# Setup optimizer for fine-tuning
optimizer = AdamW(model.parameters(), lr=LEARNING_RATE / 2, weight_decay=0.01)  # Lower LR for fine-tuning
scheduler = get_linear_schedule_with_warmup(optimizer, 0, total_pruning_steps)

# Fine-tune with pruning
print("\nStarting pruning fine-tuning...")
model.train()
global_step = 0

for epoch in range(pruning_epochs):
    print(f"\nPruning Epoch {epoch + 1}/{pruning_epochs}")
    epoch_loss = 0

    progress_bar = tqdm(train_dataloader, desc="Pruning")
    for batch in progress_bar:
        # Calculate and apply current sparsity
        current_sparsity = get_sparsity_for_step(global_step, total_pruning_steps, initial_sparsity, final_sparsity)

        if global_step % 100 == 0:
            apply_pruning(model, prunable_layers, current_sparsity)

        input_ids = batch[0].to(DEVICE)
        attention_mask = batch[1].to(DEVICE)
        labels = batch[2].to(DEVICE)

        model.zero_grad()
        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)
        loss = outputs.loss

        loss.backward()
        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)
        optimizer.step()
        scheduler.step()

        epoch_loss += loss.item()
        global_step += 1

        progress_bar.set_postfix({
            'loss': f'{loss.item():.4f}',
            'sparsity': f'{current_sparsity:.2f}'
        })

    avg_loss = epoch_loss / len(train_dataloader)
    actual_sparsity = calculate_sparsity(model, prunable_layers)

    val_accuracy, val_loss = evaluate_model(model, val_dataset)
    print(f"Epoch {epoch + 1} - Train Loss: {avg_loss:.4f}, Val Loss: {val_loss:.4f}")
    print(f"Val Accuracy: {val_accuracy:.4f}, Sparsity: {actual_sparsity*100:.2f}%")

# Make pruning permanent
for name, module in prunable_layers:
    if prune.is_pruned(module):
        prune.remove(module, 'weight')

final_sparsity = calculate_sparsity(model, prunable_layers)

# Save pruned model
pruned_model_path = os.path.join(OUTPUT_DIR, 'pruned_model')
os.makedirs(pruned_model_path, exist_ok=True)
model.save_pretrained(pruned_model_path)
tokenizer.save_pretrained(pruned_model_path)

print(f"\nPruned model saved to: {pruned_model_path}")

# ============================================================================
# STEP 3: Test multiple sparsity levels (50% to 80%)
# ============================================================================

print("\n" + "="*80)
print("STEP 3: TESTING MULTIPLE SPARSITY LEVELS")
print("="*80)

# Test at different sparsity levels
sparsity_levels = [0.0, 0.50, 0.55, 0.60, 0.65, 0.70, 0.75, 0.80]
test_accuracies = []

print("\nTesting different sparsity levels...")

for sparsity in sparsity_levels:
    # Reload baseline model
    model = DistilBertForSequenceClassification.from_pretrained(baseline_model_path)
    model.to(DEVICE)

    if sparsity > 0:
        # Apply pruning
        prunable_layers = []
        for name, module in model.named_modules():
            if isinstance(module, torch.nn.Linear) and 'classifier' not in name and 'pre_classifier' not in name:
                prunable_layers.append((name, module))

        for name, module in prunable_layers:
            prune.l1_unstructured(module, name='weight', amount=sparsity)

        # Calculate actual sparsity
        actual_sparsity = calculate_sparsity(model, prunable_layers)
    else:
        actual_sparsity = 0.0

    # Evaluate
    accuracy, _ = evaluate_model(model, val_dataset)
    test_accuracies.append(accuracy)

    compression_ratio = 1 / (1 - actual_sparsity) if actual_sparsity < 1 else float('inf')
    print(f"Sparsity: {sparsity*100:5.1f}% ‚Üí Accuracy: {accuracy:.4f} (Compression: {compression_ratio:.1f}√ó)")

# ============================================================================
# STEP 4: Plot results (like reference image)
# ============================================================================

print("\n" + "="*80)
print("STEP 4: GENERATING VISUALIZATION")
print("="*80)

# Create plot like the reference image
fig, ax1 = plt.subplots(figsize=(12, 7))

# Calculate compression ratios
compression_ratios = [f"{(1/(1-s)):.1f}√ó" if s > 0 else "1.0√ó" for s in sparsity_levels]

# Plot baseline as horizontal dashed line
ax1.axhline(y=baseline_accuracy, color='red', linestyle='--', linewidth=2.5,
            label=f'Baseline Model: {baseline_accuracy:.3f}', zorder=1)

# Plot pruned model accuracies
sparsity_percent = [s * 100 for s in sparsity_levels]
ax1.plot(sparsity_percent, test_accuracies, 'o-', color='#1f77b4',
         linewidth=2.5, markersize=10, label='Magnitude Pruning', zorder=2)

# Highlight best pruned accuracy
best_idx = np.argmax(test_accuracies[1:]) + 1  # Skip baseline at index 0
best_sparsity = sparsity_levels[best_idx]
best_accuracy = test_accuracies[best_idx]
ax1.scatter([best_sparsity*100], [best_accuracy], color='black', s=200,
           marker='o', edgecolors='yellow', linewidth=3, zorder=3)
ax1.annotate(f'Best: {best_accuracy:.3f}\n(k={best_sparsity*100:.0f}%)',
            xy=(best_sparsity*100, best_accuracy),
            xytext=(best_sparsity*100, best_accuracy - 0.015),
            fontsize=10, ha='center',
            bbox=dict(boxstyle='round,pad=0.5', facecolor='yellow', alpha=0.7))

# Set labels and title
ax1.set_xlabel('Sparsity (%)', fontsize=13, fontweight='bold')
ax1.set_ylabel('Test / Accuracy', fontsize=13, fontweight='bold')
ax1.set_title('DistilBERT SST-2: Magnitude-Based Pruning Performance',
              fontsize=14, fontweight='bold')

# Add compression ratio as top x-axis
ax2 = ax1.twiny()
ax2.set_xlim(ax1.get_xlim())
ax2.set_xticks(sparsity_percent)
ax2.set_xticklabels(compression_ratios, fontsize=9)
ax2.set_xlabel('Compression Ratio', fontsize=12, fontweight='bold')

# Grid and legend
ax1.grid(True, alpha=0.3, linestyle='--')
ax1.legend(loc='lower left', fontsize=11, framealpha=0.9)

# Set y-axis limits
y_min = min(test_accuracies + [baseline_accuracy]) - 0.01
y_max = max(test_accuracies + [baseline_accuracy]) + 0.01
ax1.set_ylim([y_min, y_max])

# Save plot
plot_path = os.path.join(OUTPUT_DIR, 'pruning_comparison.png')
plt.tight_layout()
plt.savefig(plot_path, dpi=300, bbox_inches='tight', facecolor='white')
print(f"\n‚úì Plot saved to: {plot_path}")
plt.show()

# ============================================================================
# FINAL SUMMARY
# ============================================================================

print("\n" + "="*80)
print("üìä FINAL SUMMARY")
print("="*80)
print(f"Baseline test accuracy:        {baseline_accuracy:.4f} ({baseline_accuracy*100:.2f}%)")
print(f"Best pruned accuracy:          {best_accuracy:.4f} ({best_accuracy*100:.2f}%)")
print(f"Best sparsity level:           {best_sparsity*100:.0f}%")
print(f"Accuracy at 80% sparsity:      {test_accuracies[-1]:.4f} ({test_accuracies[-1]*100:.2f}%)")
print(f"Accuracy drop at 80%:          {(baseline_accuracy - test_accuracies[-1])*100:.2f}%")
print(f"\nüìÅ Baseline model: {baseline_model_path}")
print(f"üìÅ Pruned model: {pruned_model_path}")
print(f"üìä Comparison plot: {plot_path}")
print("="*80)